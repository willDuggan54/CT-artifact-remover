{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FBPConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgEyD64EPvZD"
      },
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk2kuVoqKKfK"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeI_Oj_WRQRV"
      },
      "source": [
        "Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cbtc_DCRSd2"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "path = '/content/drive/MyDrive/GAN_Data/trainingDataNC/truth_small'\n",
        "path2 = '/content/drive/MyDrive/GAN_Data/trainingDataNC/artifact_10x_small'\n",
        "BATCH_SIZE = 1\n",
        "THETA = 1\n",
        "COUNT = 0\n",
        "EPOCHS= 50\n",
        "LR = 0.01\n",
        "\n",
        "def load_image(image):\n",
        "  image = tf.io.read_file(image)\n",
        "  image = tf.image.decode_png(image)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return image\n",
        "\n",
        "def normalize(image):\n",
        "  image = (image/127.5)-1\n",
        "  return image\n",
        "\n",
        "def preprocess(image):\n",
        "  image = load_image(image)\n",
        "  image = normalize(image)\n",
        "  return image\n",
        "\n",
        "truth_dataset = tf.data.Dataset.list_files(path + '/*.png', shuffle=False)\n",
        "truth_dataset = truth_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "truth_dataset = truth_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "artifact_dataset = tf.data.Dataset.list_files(path2 + '/*.png', shuffle=False)\n",
        "artifact_dataset = artifact_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "artifact_dataset = artifact_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyMVV8505TLO"
      },
      "source": [
        "def crop(image_a, image_t):\n",
        "  image_a = tf.reshape(image_a, [1,542,542,1])\n",
        "  image_t = tf.reshape(image_t, [1,542,542,1])\n",
        "  combined_image = tf.concat([image_a, image_t], axis=0)\n",
        "  cropped = tf.image.random_crop(combined_image, size=[2, 512, 512, 1])\n",
        "  return cropped[0], cropped[1]\n",
        "\n",
        "def resize(image_a, image_t):\n",
        "  image_a = tf.image.resize(images=image_a, size=[542,542], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  image_t = tf.image.resize(images=image_t, size=[542,542], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return image_a, image_t\n",
        "\n",
        "def random_jittering(image_a, image_t):\n",
        "  image_a, image_t = resize(image_a, image_t)\n",
        "  image_a, image_t = crop(image_a, image_t)\n",
        "  if (tf.random.uniform(shape=[1]) >= 0.5):\n",
        "    image_a = tf.image.flip_left_right(image_a)\n",
        "    image_t = tf.image.flip_left_right(image_t)\n",
        "  return image_a, image_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lftiZBp15T79"
      },
      "source": [
        "def transform_dataset(truth_dataset, artifact_dataset):\n",
        "  temp_truth = []\n",
        "  temp_art = []\n",
        "  for t_images, a_images in zip(truth_dataset, artifact_dataset):\n",
        "    a_images, t_images = random_jittering(a_images, t_images)\n",
        "    temp_truth.append(t_images)\n",
        "    temp_art.append(a_images)\n",
        "  truth_dataset = tf.data.Dataset.from_tensor_slices(temp_truth)\n",
        "  artifact_dataset = tf.data.Dataset.from_tensor_slices(temp_art)\n",
        "  return truth_dataset, artifact_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL6HXvmXRYq0"
      },
      "source": [
        "Creating the ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Mn500ERedE"
      },
      "source": [
        "def down(filters, prev):\n",
        "  initializer = tf.keras.initializers.HeNormal()\n",
        "  x = tf.keras.layers.Conv2D(filters, (3,3), strides=(1,1), padding='same', kernel_initializer=initializer)(prev)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-1wpTA4QcdR"
      },
      "source": [
        "def up(filtersFirst,filtersSec, prev, skip):\n",
        "  initializer = tf.keras.initializers.HeNormal()\n",
        "  x = tf.keras.layers.Concatenate()([prev, skip])\n",
        "  x = tf.keras.layers.Conv2D(filtersFirst, (3,3), strides=(1,1), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = tf.keras.layers.Conv2D(filtersSec, (3,3), strides=(1,1), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlzhZvoRaj-"
      },
      "source": [
        "def create_convNet_model():\n",
        "  initializer = tf.keras.initializers.HeNormal()\n",
        "  input = tf.keras.layers.Input(shape=[512, 512, 1])\n",
        "  x = down(1, input)\n",
        "  x = down(64, x)\n",
        "  skip1 = down(64, x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(skip1)\n",
        "  x = down(64, x)\n",
        "  skip2 = down(128, x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(skip2)\n",
        "  x = down(128, x)\n",
        "  skip3 = down(256, x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(skip3)\n",
        "  x = down(256, x)\n",
        "  skip4 = down(512, x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(skip4)\n",
        "  x = down(512, x)\n",
        "  x = down(1024, x)\n",
        "  x = down(1024, x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(1024, (3,3), strides=(2,2), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = up(1024, 512, x, skip4)\n",
        "  x = tf.keras.layers.Conv2DTranspose(512, (3,3), strides=(2,2), padding='same',kernel_initializer=initializer)(x)\n",
        "  x = up(512, 256, x, skip3)\n",
        "  x = tf.keras.layers.Conv2DTranspose(256, (3,3), strides=(2,2), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = up(256, 128, x, skip2)\n",
        "  x = tf.keras.layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = up(128, 64, x, skip1)\n",
        "  x = tf.keras.layers.Conv2D(1, (1,1), strides=(1,1), padding='same', kernel_initializer=initializer)(x)\n",
        "  x = tf.keras.layers.Add()([input,x])\n",
        "  output = tf.keras.layers.Activation('tanh')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input], outputs=[output])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg46aemA-zW_"
      },
      "source": [
        "def get_loss(generated_image, truth_image):\n",
        "  loss = tf.reduce_mean((generated_image - truth_image)**2)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CpzuLrLYdIu"
      },
      "source": [
        "def log_decay(rate, epochs):\n",
        "  if epochs != 0:\n",
        "    rate = -0.1*math.log10(CHANGE-RATE) #.795, .977\n",
        "    if rate < 0.001:\n",
        "      rate = 0.001\n",
        "  return rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phVVQlA-OCk"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnOx3GM8-Pjf"
      },
      "source": [
        "def train(truth_dataset, artifact_dataset, epochs):\n",
        "  global COUNT\n",
        "  for i in range(epochs): #Outer loops is for number of epochs\n",
        "    print('Epoch: ', i)\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=log_decay(LR, epochs), momentum=0.99, clipvalue=0.1) #This is only here because I used learning rate decay in this model\n",
        "    #If that is not needed, can establish optimizer outside of loop\n",
        "    if i % 10 == 0: #Used to save model every 10 epochs\n",
        "      saveModel(model, i)\n",
        "    show = True\n",
        "    for t_images, a_images in zip(truth_dataset, artifact_dataset): #Inner loop is for every element in the dataset\n",
        "    #I am using a tf dataset, so I can manually batch the datasets and this loop will get a batch size amount of elements \n",
        "      print('.', end='')\n",
        "      train_step(truth_image=t_images, artifact_image=a_images, show=show)\n",
        "      show = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4COYODsK-UqW"
      },
      "source": [
        "def train_step(artifact_image, truth_image, show):\n",
        "  with tf.GradientTape() as Conv_tape:\n",
        "    generated_images = model(artifact_image, training=True) #predicting using the model\n",
        "    loss = get_loss(generated_images, truth_image) #determines the loss of the prediction\n",
        "    if show:  #section is only necessary for printing output after every epoch\n",
        "      generated_images = tf.reshape(generated_images, (512,512))\n",
        "      artifact_image = tf.reshape(artifact_image, (512,512))\n",
        "      truth_image = tf.reshape(truth_image, (512,512))\n",
        "      plot_images(generated_images, artifact_image, truth_image)\n",
        "\n",
        "    gradients_of_gen = Conv_tape.gradient(loss, model.trainable_variables) #gets the gradients from the loss using the GradientTape\n",
        "    optimizer.apply_gradients(zip(gradients_of_gen, model.trainable_variables)) #applies the gradients using the optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgJwjOzr-chk"
      },
      "source": [
        "def plot_images(prediction, input, target):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  display_list = [input, target, prediction]\n",
        "  title = ['Artifacted Image', 'Ground Truth Image', 'Generated Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[i]*0.5 +0.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slGnVjBH_6SG"
      },
      "source": [
        "def saveModel(generator, epoch):\n",
        "  if epoch != 0:\n",
        "    name = 'FBPConv_e' + str(epoch) +'.h5'\n",
        "    model.save(name)\n",
        "    !cp $name \"/content/drive/MyDrive/GAN_Data/Models\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MFSB6yRS5eA"
      },
      "source": [
        "\n",
        "truth_dataset, artifact_dataset = transform_dataset(truth_dataset, artifact_dataset)\n",
        "truth_dataset = truth_dataset.batch(BATCH_SIZE)\n",
        "artifact_dataset = artifact_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "model = create_convNet_model()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)\n",
        "RATE = (.977-.795)/EPOCHS\n",
        "CHANGE = .977\n",
        "#lr_scheduler = tf.keras.optimizers.schedules.ExponentialDeca y(initial_learning_rate=0.01, decay_steps=1, decay_rate=0.743)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=LR, momentum=0.99, clipvalue=0.1)\n",
        "train(truth_dataset, artifact_dataset, EPOCHS)\n",
        "\n",
        "model.save('FBPConv.h5')\n",
        "!cp FBPConv.h5 \"/content/drive/MyDrive/GAN_Data/Models\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
