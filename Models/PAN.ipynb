{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H64Q5RBcHdm7"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJah4wYTHoxP"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwivw9UsHF29"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHg_TseHwdf"
      },
      "source": [
        "Image input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAGZBDI6H03_"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "path = '/content/drive/MyDrive/GAN_Data/trainingDataNC/truth_small'\n",
        "path2 = '/content/drive/MyDrive/GAN_Data/trainingDataNC/artifact_10x_small'\n",
        "BATCH_SIZE = 4\n",
        "THETA = 1.5\n",
        "MARGIN = 3\n",
        "COUNT = 0\n",
        "EPOCHS = 400\n",
        "\n",
        "def load_image(image):\n",
        "  image = tf.io.read_file(image)\n",
        "  image = tf.image.decode_png(image)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return image\n",
        "\n",
        "def normalize(image):\n",
        "  image = (image/127.5)-1\n",
        "  return image\n",
        "\n",
        "def preprocess(image):\n",
        "  image = load_image(image)\n",
        "  image = normalize(image)\n",
        "  return image\n",
        "\n",
        "truth_dataset = tf.data.Dataset.list_files(path + '/*.png', shuffle=False)\n",
        "truth_dataset = truth_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#truth_dataset = truth_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "artifact_dataset = tf.data.Dataset.list_files(path2 + '/*.png', shuffle=False)\n",
        "artifact_dataset = artifact_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#artifact_dataset = artifact_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEFkVqvZhIRM"
      },
      "source": [
        "**Helper Functions for Transform Dataset Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qJG7dBhMi8"
      },
      "source": [
        "def crop(image_a, image_t):\n",
        "  image_a = tf.reshape(image_a, [1,542,542,1])\n",
        "  image_t = tf.reshape(image_t, [1,542,542,1])\n",
        "  combined_image = tf.concat([image_a, image_t], axis=0)\n",
        "  cropped = tf.image.random_crop(combined_image, size=[2, 512, 512, 1])\n",
        "  return cropped[0], cropped[1]\n",
        "\n",
        "def resize(image_a, image_t):\n",
        "  image_a = tf.image.resize(images=image_a, size=[542,542], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  image_t = tf.image.resize(images=image_t, size=[542,542], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return image_a, image_t\n",
        "\n",
        "def random_jittering(image_a, image_t):\n",
        "  image_a, image_t = resize(image_a, image_t)\n",
        "  image_a, image_t = crop(image_a, image_t)\n",
        "  if (tf.random.uniform(shape=[1]) >= 0.5):\n",
        "    image_a = tf.image.flip_left_right(image_a)\n",
        "    image_t = tf.image.flip_left_right(image_t)\n",
        "  return image_a, image_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C5LT3jDgsUe"
      },
      "source": [
        "**Transform Dataset Method:**\n",
        "This method applies the random jittering (random crop and flipping) to the images. This helps the network learn how to better generalize and helps to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elQqTbPug-lm"
      },
      "source": [
        "def transform_dataset(truth_dataset, artifact_dataset):\n",
        "  temp_truth = []\n",
        "  temp_art = []\n",
        "  for t_images, a_images in zip(truth_dataset, artifact_dataset):\n",
        "    a_images, t_images = random_jittering(a_images, t_images)\n",
        "    temp_truth.append(t_images)\n",
        "    temp_art.append(a_images)\n",
        "  truth_dataset = tf.data.Dataset.from_tensor_slices(temp_truth)\n",
        "  artifact_dataset = tf.data.Dataset.from_tensor_slices(temp_art)\n",
        "  return truth_dataset, artifact_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkeQsfhIEx5"
      },
      "source": [
        "# Creating the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RHIlMm3IHb4"
      },
      "source": [
        "Defining the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzNORKVKIJ9G"
      },
      "source": [
        "def conv_layer(filters, strides, input_layer, apply_batchnorm=True):\n",
        "  init = tf.random_normal_initializer(0. , 0.02)\n",
        "  x = tf.keras.layers.Conv2D(filters, (3,3), strides, padding='same', kernel_initializer=init)(input_layer)\n",
        "  if apply_batchnorm:\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def create_discriminator_model():\n",
        "  init = tf.random_normal_initializer(0. , 0.02)\n",
        "  input = tf.keras.layers.Input(shape=[512,512,1])\n",
        "  x = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(input)\n",
        "  D1 = tf.keras.layers.LeakyReLU(0.2)(x)\n",
        "  #First perceptual loss D1\n",
        "  x = conv_layer(128, (2,2), D1)\n",
        "  x = conv_layer(128, (1,1), x)\n",
        "  D2 = conv_layer(256, (2,2), x)\n",
        "  #Second perceptual loss D2\n",
        "  x = conv_layer(256, (1,1), D2)\n",
        "  D3 = conv_layer(512, (2,2), x)\n",
        "  #Third perceptual loss D3\n",
        "  x = conv_layer(512, (1,1), D3)\n",
        "  D4 = conv_layer(512, (2,2), x)\n",
        "  #Fourth perceptual loss D4\n",
        "  x = conv_layer(8, (2,2), D4, apply_batchnorm=False)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input], outputs=[output, D1, D2, D3, D4])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emcsssd_IPC3"
      },
      "source": [
        "Discriminator Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcc0sz4aIUFB"
      },
      "source": [
        "def get_discriminator_loss(percep_loss, real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  binary_loss = -1*THETA*(real_loss + fake_loss)\n",
        "  percep_loss = MARGIN - percep_loss\n",
        "  if percep_loss < 0:\n",
        "    percep_loss = 0\n",
        "  return binary_loss + percep_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDBeE29NIXkB"
      },
      "source": [
        "Defining the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9-_DogiIbEo"
      },
      "source": [
        "def encoder(filters, prev, batchnorm=True):\n",
        "  init = tf.random_normal_initializer(0. , 0.02)\n",
        "  x= tf.keras.layers.Conv2D(filters, (3,3), strides=(2,2), kernel_initializer=init, padding='same')(prev)\n",
        "  if batchnorm:\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "  return x\n",
        "\n",
        "def decoder(filters, prev, skip, dropout=False):\n",
        "  init = tf.random_normal_initializer(0. , 0.02)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(prev)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  if dropout:\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skip])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "def create_generator_model():\n",
        "  init = tf.random_normal_initializer(0. , 0.02)\n",
        "  input = tf.keras.layers.Input(shape=[512, 512, 1])\n",
        "  enc0 = encoder(64, prev=input, batchnorm=False)\n",
        "  enc1 = encoder(128, prev=enc0)\n",
        "  enc2 = encoder(256, prev=enc1)\n",
        "  enc3 = encoder(512, prev=enc2)\n",
        "  enc4 = encoder(512, prev=enc3)\n",
        "\n",
        "  mid = tf.keras.layers.Conv2D(512, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(enc4)\n",
        "  mid = tf.keras.layers.BatchNormalization()(mid)\n",
        "  mid = tf.keras.layers.LeakyReLU(alpha=0.2)(mid)\n",
        "\n",
        "  dec0 = decoder(512, prev=mid, skip=enc4, dropout=True)\n",
        "  dec1 = decoder(256, prev=dec0, skip=enc3, dropout=True)\n",
        "  dec2 = decoder(128, prev=dec1, skip=enc2, dropout=True)\n",
        "  dec3 = decoder(64, prev=dec2, skip=enc1)\n",
        "  x = tf.keras.layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(dec3)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(x)\n",
        "  output = tf.keras.layers.Activation('tanh')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX1HyRcCpQMd"
      },
      "source": [
        "Generator Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNQyvGZhpR7E"
      },
      "source": [
        "def get_generator_loss(percep_loss, fake_output):\n",
        "  gan_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return THETA*gan_loss + percep_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MlgljVBYNOy"
      },
      "source": [
        "Perceptual Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN-q68YNYPdi"
      },
      "source": [
        "def get_perceptual_loss(tD1, tD2, tD3, tD4, gD1, gD2, gD3, gD4):\n",
        "  D1_loss = tf.reduce_mean(tf.abs(tD1-gD1))\n",
        "  D2_loss = tf.reduce_mean(tf.abs(tD2-gD2))\n",
        "  D3_loss = tf.reduce_mean(tf.abs(tD3-gD3))\n",
        "  D4_loss = tf.reduce_mean(tf.abs(tD4-gD4))\n",
        "  return 5*D1_loss + 1.5*D2_loss + 1.5*D3_loss + D4_loss  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkThiKgaZ236"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0wSUEnVZ7xU"
      },
      "source": [
        "Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y-p_rwkZ9l7"
      },
      "source": [
        "def train(truth_dataset, artifact_dataset, epochs, count):\n",
        "  global COUNT\n",
        "  for i in range(epochs):\n",
        "    print('Epoch: ', i)\n",
        "    if i % 40 == 0:\n",
        "      saveModel(generator, i)\n",
        "    show = True\n",
        "    for t_images, a_images in zip(truth_dataset, artifact_dataset):\n",
        "      print('.', end='')\n",
        "      train_step(truth_image=t_images, artifact_image=a_images, show=show, count=count)\n",
        "      count +=1\n",
        "      show = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E31yRlNlaDxT"
      },
      "source": [
        "Train Step Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfVGsJHXaFP7"
      },
      "source": [
        "def train_step(artifact_image, truth_image, show, count):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as discriminator_tape:\n",
        "    generated_images = generator(artifact_image, training=True)\n",
        "    real_output, tD1, tD2, tD3, tD4 = model_discriminator(truth_image, training=True)\n",
        "    fake_output, gD1, gD2, gD3, gD4 = model_discriminator(generated_images, training=True)\n",
        "    if show:\n",
        "      generated_images ,_ ,_ ,_ = tf.unstack(generated_images, axis=0)\n",
        "      generated_images = tf.reshape(generated_images, (512,512))\n",
        "      artifact_image ,_ ,_ ,_ = tf.unstack(artifact_image, axis=0)\n",
        "      artifact_image = tf.reshape(artifact_image, (512,512))\n",
        "      truth_image ,_ ,_ ,_ = tf.unstack(truth_image, axis=0)\n",
        "      truth_image = tf.reshape(truth_image, (512,512))\n",
        "      plot_images(generated_images, artifact_image, truth_image)\n",
        "\n",
        "    percep_loss = get_perceptual_loss(tD1, tD2, tD3, tD4, gD1, gD2, gD3, gD4)\n",
        "    if count %3 == 0:\n",
        "      discriminator_loss = get_discriminator_loss(percep_loss, real_output, fake_output)\n",
        "      disc_points.append(discriminator_loss)\n",
        "      #print('Disc Loss: ', discriminator_loss)\n",
        "      gradients_of_disc = discriminator_tape.gradient(discriminator_loss, model_discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_disc, model_discriminator.trainable_variables))\n",
        "\n",
        "    gen_loss = get_generator_loss(percep_loss, fake_output)\n",
        "    #print(gen_loss)\n",
        "   # print('Gen Loss: ', gen_loss)\n",
        "    gradients_of_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_gen, generator.trainable_variables))\n",
        "    gen_points.append(gen_loss)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ori2lgdtqvQk"
      },
      "source": [
        "Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxU6wzzoqwkk"
      },
      "source": [
        "def saveModel(generator, epoch):\n",
        "  name = 'PAN_e' + str(epoch) +'.h5'\n",
        "  generator.save(name)\n",
        "  !cp $name \"/content/drive/MyDrive/GAN_Data/Models/PAN_test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-R0tPEqrDR-"
      },
      "source": [
        "Plot the Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9pSslkYrEg7"
      },
      "source": [
        "def plot_images(prediction, input, target):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  display_list = [input, target, prediction]\n",
        "  title = ['Artifacted Image', 'Ground Truth Image', 'Generated Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[i]*0.5 +0.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCG0MRq7R3tc"
      },
      "source": [
        "def plot_loss(gen_points, disc_points):\n",
        "  x_gen = []\n",
        "  x_disc= []\n",
        "  for i in range(0, len(gen_points)):\n",
        "    x_gen.append(i)\n",
        "  for j in range(0, len(disc_points)):\n",
        "    x_disc.append(j)\n",
        "  plt.plot(x_gen, gen_points, label = 'gen')\n",
        "  plt.plot(x_disc, disc_points, label = 'disc')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Iteration')\n",
        "  plt.title('Loss values over time')\n",
        "  plt.legend()\n",
        "  plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZVdA5Xda5LM"
      },
      "source": [
        "# \"Main\" Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pcIyhrJCa9Vq"
      },
      "source": [
        "truth_dataset, artifact_dataset = transform_dataset(truth_dataset, artifact_dataset)\n",
        "truth_dataset = truth_dataset.batch(BATCH_SIZE)\n",
        "artifact_dataset = artifact_dataset.batch(BATCH_SIZE)\n",
        "#It is important to batch the datasets again after transforming the images to get the desired shape for each image i.e. [1, 512, 512, 1]\n",
        "\n",
        "model_discriminator = create_discriminator_model()\n",
        "discriminator_optimizer = tf.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
        "print('Created Discriminator!')\n",
        "tf.keras.utils.plot_model(model_discriminator, show_shapes=True, dpi=64)\n",
        "\n",
        "generator = create_generator_model()\n",
        "generator_optimizer = tf.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
        "\n",
        "print('Created Generator!')\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "gen_points = []\n",
        "disc_points = []\n",
        "#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
        "train(truth_dataset, artifact_dataset, EPOCHS, COUNT)\n",
        "\n",
        "generator.save('PAN_FIN.h5')\n",
        "!cp PAN_FIN.h5 \"/content/drive/MyDrive/GAN_Data/Models/PAN_test\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
